<!doctype html>
<html lang="en">

<head>
  <script src="./javascripts/baff6f55f5.js"></script>
  <!-- <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script> -->
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Kun Song</title>

  <link rel="stylesheet" href="stylesheets/styles.css">
  <!-- <link rel="stylesheet" href="stylesheets/github-light.css"> -->
  <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=yes">
  <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->

  <!-- <script>
    (function (i, s, o, g, r, a, m) {
      i['GoogleAnalyticsObject'] = r; i[r] = i[r] || function () {
        (i[r].q = i[r].q || []).push(arguments)
      }, i[r].l = 1 * new Date(); a = s.createElement(o),
        m = s.getElementsByTagName(o)[0]; a.async = 1; a.src = g; m.parentNode.insertBefore(a, m)
    })(window, document, 'script', 'https://www.google-analytics.com/analytics.js', 'ga');

    ga('create', 'UA-29643011-3', 'auto');
    ga('send', 'pageview');
  </script> -->



  <!-- For all browsers -->
  <link rel="stylesheet" href="assets/css/academicons.min.css" />
  <link rel="stylesheet" href="assets/css/academicons.css" />

  <style>
    button.accordion {
      font: 14px/1.5 Lato, "Helvetica Neue", Helvetica, Arial, sans-serif;
      cursor: pointer;
      padding: 0px;
      border: none;
      text-align: left;
      outline: none;
      font-size: 100%;
      transition: 0.3s;
      background-color: #f8f8f8;
    }

    button.accordion.active,
    button.accordion:hover {
      background-color: #f8f8f8;
    }

    button.accordion:after {
      content: " [+] ";
      font-size: 90%;
      color: #777;
      float: left;
      margin-left: 1px;
    }

    button.accordion.active:after {
      content: " [\2212] ";
    }

    div.panel {
      padding: 0 20px;
      margin-top: 5px;
      display: none;
      background-color: white;
      font-size: 100%;
    }

    div.panel.show {
      display: block !important;
    }

    .social-row {
      display: flex;
      flex-wrap: wrap;
      justify-content: space-between;
    }

    .scrollable-list {
  max-height: 150px; /* 调整高度 */
  overflow-y: auto;  /* 启用垂直滚动 */
  border: 2px solid #2e95f4; /* 绿色边框 */
  border-radius: 10px; /* 圆角边框 */
  padding: 10px;
  background: linear-gradient(to bottom, #f9f9f9, #b9e4f0); /* 渐变背景 */
  box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1); /* 添加阴影 */
}

/* 自定义滚动条样式 */
.scrollable-list::-webkit-scrollbar {
  width: 8px;
}

.scrollable-list::-webkit-scrollbar-track {
  background: #f1f1f1; 
  border-radius: 10px;
}

.scrollable-list::-webkit-scrollbar-thumb {
  background: #6b6b6b; 
  border-radius: 10px;
}

.scrollable-list::-webkit-scrollbar-thumb:hover {
  background: #3e3e3e;
}


  </style>
</head>

<body>
  <div class="wrapper">
    <header class="left-section">
      <img src="img/sk3.jpg" height="240" width="240" alt="Kun Song" text-align:center></h3>
      <h1>Kun Song </h1>
      <h3><a href="https://song-kun.github.io/">Home</a></h3>
      <h3><a href="./research/CV.pdf">CV</a></h3>


      <!-- <b>social</b><br> -->
      <div class="social-row">
        <a href="https://scholar.google.com/citations?hl=zh-CN&user=ZGuZ_FoAAAAJ" target="_blank"><i
            class="ai ai-fw ai-google-scholar-square"></i> Scholar</a><br>
        <a href="https://github.com/song-kun"><i class="fa fa-fw fa-github-square"></i> GitHub</a><br>
        <a href="https://www.linkedin.com/in/kunsong-b094a7300" target="_blank"><i
            class="fa fa-fw fa-linkedin-square"></i> LinkedIn</a><br>
      </div>

      <p><br><b>Contact:</b>
        <br>The University of Hong Kong
        <br>Pokfulam Road, Hong Kong
        <br>kunsonghku@connect.hku.hk
      </p>
      
      <!-- <script type="text/javascript" id="clstr_globe" src="//clustrmaps.com/globe.js?d=oz9bKgR2vKBdG76LxLgjmeBj6UZq8zrWxKwuZ0bUDqE"></script>-->            
      <script type="text/javascript"
        language="javascript">document.write("Last updated: " + document.lastModified);
      </script>
      </p>
    </header>

    <section class="right-section">
      <section>
        <h2><a id="Intro" class="anchor" href="#publications" aria-hidden="true"><span
              class="octicon octicon-link"></span></a> About Me </h2>
        <p>I am a Ph.D. sutdent in CS department in The University of Hong Kong (HKU) adviced by <a href="https://sites.google.com/site/panjia/" target="_blank">Jia Pan</a>.
        Before that, I obtained my master's degree in <a href="https://github.com/RobotControlAndMachineVisionLaboratory"
            target="_blank">RCMVL</a> (Robot Control and Machine Vision Lab) of Shanghai Jiao Tong University (SJTU) advised by Prof. Zhenhua Xiong in 2025. I got my bachelor degree in Mechanical Engeering with honor from SJTU in 2022.</p>
          
        <p>In 2024, I was a research assistant in <a href="https://msc.berkeley.edu/" target="_blank">MSC-Lab</a> at UC Berkely advised by <a href="https://me.berkeley.edu/people/masayoshi-tomizuka/" target="_blank">Prof. Masayoshi Tomizuka</a> and <a href="https://dingmyu.github.io/" target="_blank">Prof. Mingyu Ding</a>.</p>
        
        <p>I am generally interested in enabling robotics systems, like autonomous cars, mobile manipulators, multi-robot system, and humanoids, to interact with the environment intelligently and safely. To be more specific, my research topics lie in the crossing field of perception, planning, control, optimization, foundation models, reinforcement learning, and imitation learning.
        <ul>
          <li><b>Robot Learning</b>: Reinforcement Learning, Imitation Learning, VLA, LLM, VLM, Diffusion Model;</li>
          <li><b>Multi-robot System</b>: Cooperative Manipulation, Multi-robot SLAM, Formation Control, Relative Pose Accuracy in a Swarm;</li>
          <li><b>Robot Perception</b>: Scene Understanding, SLAM System, Light-weight Mapping;</li>
          <!-- <li><b>Path/Motion Planning</b>: path/motion planning for mobile manipulator, path planning for multi-robot system.</li> -->
        </ul>
          Currently, I am working on using <b>VLM/VLA</b> for collaborative manipulation and <b>humanoid robots</b>.
          I am open for the opportunty of collaboration. Feel free to contact me if there's anything I can help you.
        </p>

        <h2>
          <a id="news" class="anchor" href="#publications" aria-hidden="true"><span
              class="octicon octicon-link"></span></a> News and Updates
        </h2>
        <!-- <li>
          <i>Mar. 2025:</i>
          Our paper (<em>planning for mobile manipulators</em>) was accepted by RA-L<br>
        </li>
        <li>
          <i>Jan. 2025:</i>
          Our paper (<em>containmen control</em>) was accepted by TRO, congratulations for Ren<br>
        </li>
        <li>
          <i>Aug. 2024:</i>
          Our paper (<em>multi-robot rendezvous</em>) was accepted by RA-L<br>
        </li>
        <li>
          <i>May 2024:</i>
          Our paper (<em>RHAML</em>) was accepted by RA-L<br>
        </li>
        <li>
          <i>Apr. 2024:</i>
          Our paper (<em>FHT-Map</em>) was accepted by RA-L<br>
        </li>
        <li>
          <i>Jan. 2024:</i>
          Create this website<br>
        </li> -->
        <div class="scrollable-list">
          <ul>
            <li>
            <i>Octo. 2025:</i>
              Our paper (<em>CollaBot</em>) was accepted by IROS 2025 CIM Workshop<br>
            </li>
            <li>
            <i>Jun. 2025:</i>
              Our paper (<em>P2 Explore</em>) was accepted by IROS 2025<br>
            </li>
            <li>
              <i>Mar. 2025:</i>
              Our paper (<em>planning for mobile manipulators</em>) was accepted by RA-L<br>
            </li>
            <li>
              <i>Jan. 2025:</i>
              Our paper (<em>containmen control</em>) was accepted by TRO, congratulations for Ren<br>
            </li>
            <li>
              <i>Aug. 2024:</i>
              Our paper (<em>multi-robot rendezvous</em>) was accepted by RA-L<br>
            </li>
            <li>
              <i>May 2024:</i>
              Our paper (<em>RHAML</em>) was accepted by RA-L<br>
            </li>
            <li>
              <i>Apr. 2024:</i>
              Our paper (<em>FHT-Map</em>) was accepted by RA-L<br>
            </li>
            <li>
              <i>Jan. 2024:</i>
              Create this website<br>
            </li>
          </ul>
        </div>

     

        <p>

        <h2><a id="published-papers-updated" class="anchor" href="#publications" aria-hidden="true">
            <span class="octicon octicon-link"></span></a>Publications</h2>
        <div>
          <small><span class="author">(* indicates equal contribution)</span></small>
        </div>

        <table
          style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
              <tr>
              <td
                style="padding:10px;width:30%;vertical-align:middle;border-left-style:none;border-bottom-style:none;border-top-style:none;border-right-style:none">
                <img src="./research/gif/move_chair.gif" alt="hpp" style="border-style: none" width="100%">
              </td>
              <td
                style="padding:10px;width:70%;vertical-align:middle;border-left-style:none;border-bottom-style:none;border-top-style:none;border-right-style:none">
                <p style="margin:0">
                  <t style="margin:0; font-size:100%; font-weight:bold"><big>CollaBot: Vision-Language Guided Simultaneous Collaborative Manipulation of Large Objects</big></t> <br>
                  <b>Kun Song</b>, Shentao Ma, Gaoming Chen, Ninglong Jin, Guangbao Zhao, Mingyu Ding, Zhenhua Xiong, and Jia Pan
                  <br><i>IROS</i>, 2025, CIM Workshop
                <div style="line-height:20px;font-size:18px;color: #777777">
                  <a href="https://arxiv.org/abs/2508.03526" target="_blank">Paper</a> /
                  <!-- <a href="https://github.com/song-kun/CollaBot" target="_blank">Website</a> / -->
                  <a href="https://github.com/song-kun/CollaBot" target="_blank">Code</a>
                </div>
                <div style="line-height:20px;font-size:14px;color: #777777">
                  We propose <var>CollaBot</var>, the first generalist framework for simultaneous collaborative manipulation.
                  First, we use SEEM for scene segmentation and point cloud extraction of the target object. 
                  Then, we propose a collaborative grasping framework, which decomposes the task into local grasp pose generation and global collaboration. 
                  Finally, we design a 2-stage planning module that can generate collision-free trajectories to achieve this task.
                </div>
              </td>
            </tr>
            <tr>
              <td
                style="padding:10px;width:30%;vertical-align:middle;border-left-style:none;border-bottom-style:none;border-top-style:none;border-right-style:none">
                <img src="./projects/p2explore/resources/exp.gif" alt="hpp" style="border-style: none" width="100%">
              </td>
              <td
                style="padding:10px;width:70%;vertical-align:middle;border-left-style:none;border-bottom-style:none;border-top-style:none;border-right-style:none">
                <p style="margin:0">
                  <t style="margin:0; font-size:100%; font-weight:bold"><big><var>P<sup>2</sup></var> Explore: Efficient Exploration in Unknown Cluttered Environment with Floor Plan Prediction</big></t> <br>
                  <b>Kun Song</b>, Gaoming Chen, Masayoshi Tomizuka, Wei Zhan, Zhenhua Xiong, and Mingyu Ding
                  <br><i>IROS</i>, 2025
                <div style="line-height:20px;font-size:18px;color: #777777">
                  <a href="https://arxiv.org/abs/2409.10878" target="_blank">Paper</a> /
                  <a href="https://song-kun.github.io/projects/p2explore" target="_blank">Website</a> /
                  <a href="https://github.com/song-kun/P2Explore" target="_blank">Code</a>
                </div>
                <div style="line-height:20px;font-size:14px;color: #777777">
                  We propose <var>P<sup>2</sup></var> Explore, a framework that predicts the unseen floor plan based in cluttered environments.
                  Based on the predicted map, we extract room segmentations and generate their topology.
                  Exploration is accelerated under the guidance of this topology.
                </div>
              </td>
            </tr>
            <tr>
              <td
                style="padding:10px;width:30%;vertical-align:middle;border-left-style:none;border-bottom-style:none;border-top-style:none;border-right-style:none">
                <img src="./research/gif/MMMPlanning.gif" alt="hpp" style="border-style: none" width="100%">
              </td>
              <td
                style="padding:10px;width:70%;vertical-align:middle;border-left-style:none;border-bottom-style:none;border-top-style:none;border-right-style:none">
                <p style="margin:0">
                  <t style="margin:0; font-size:100%; font-weight:bold"><big>A Novel Planning Framework for Complex Flipping Manipulation of Multiple Mobile Manipulators	</big></t> <br>
                  Wenhang Liu,  Meng Ren, <b>Kun Song</b>, Yu Wang, and Zhenhua Xiong
                  <br><i>Robotics and Automation Letters</i>, 2025
                <div style="line-height:20px;font-size:18px;color: #777777">
                  <a href="https://arxiv.org/abs/2312.06168" target="_blank">Paper</a>
                </div>
                <div style="line-height:20px;font-size:14px;color: #777777">
                We propose a novel planning framework for complex flipping manipulation by incorporating platform motions and regrasping. 
                We formulate the planning problem as a set cover problem and determine minimal number of regrasping.
                </div>
              </td>
            </tr>
            <tr>
              <td
                style="padding:10px;width:30%;vertical-align:middle;border-left-style:none;border-bottom-style:none;border-top-style:none;border-right-style:none">
                <img src="./research/gif/contain_control.gif" alt="hpp" style="border-style: none" width="100%">
              </td>
              <td
                style="padding:10px;width:70%;vertical-align:middle;border-left-style:none;border-bottom-style:none;border-top-style:none;border-right-style:none">
                <p style="margin:0">
                  <t style="margin:0; font-size:100%; font-weight:bold"><big>Containment Control of Multi-Robot Systems
                      with Non-uniform Time-varying Delays</big></t> <br>
                  Meng Ren, Wenhang Liu, <b>Kun Song</b>, Ling Shi, and Zhenhua Xiong
                  <br><i>IEEE Transactions on Robotics</i>, 2025
                <div style="line-height:20px;font-size:18px;color: #777777">
                  <a href="https://ieeexplore.ieee.org/abstract/document/10876769" target="_blank">Paper</a>
                </div>
                <div style="line-height:20px;font-size:14px;color: #777777">
                We propose a containment control law for double-integrator MRSs subject to non-uniform time-varying delays.
                The stability is proved by the Lyapunov-Krasovskii function and linear matrix inequalities
                </div>
              </td>
            </tr>

            <tr>
              <td
                style="padding:10px;width:30%;vertical-align:middle;border-left-style:none;border-bottom-style:none;border-top-style:none;border-right-style:none">
                <img src="./research/image/rend.jpg" alt="hpp" style="border-style: none" width="100%">
              </td>
              <td
                style="padding:10px;width:70%;vertical-align:middle;border-left-style:none;border-bottom-style:none;border-top-style:none;border-right-style:none">
                <div style="margin:0">
                  <t style="margin:0; font-size:100%; font-weight:bold"><big>Multi-Robot Rendezvous in Unknown
                      Environment with Limited Communication</big></t> <br>
                  <b>Kun Song</b>, Gaoming Chen, Wenhang Liu, and Zhenhua Xiong
                  <br><i>Robotics and Automation Letters</i>, 2024
                  </div>
                <div style="line-height:20px;font-size:18px;color: #777777">
                  <a href="https://ieeexplore.ieee.org/document/10679913" target="_blank">Paper</a> /
                  <a href="https://github.com/song-kun/Distributed-Multi-Robot-Topological-Map" target="_blank">Code</a>
                </div>
                <div style="line-height:20px;font-size:14px;color: #777777">
                We focus on rendezvous in unknown environments where communication is available. 
                We divide this task into two steps: rendezvous based environment exploration with relative pose estimation and rendezvous point selection.
                A new strategy called partitioned and incomplete exploration for rendezvous (PIER) is proposed to efficiently explore the unknown environment and a rendezvous point can be selected for efficient rendezvous.
                </div>
              </td>
            </tr>

            <tr>
              <td
                style="padding:10px;width:30%;vertical-align:middle;border-left-style:none;border-bottom-style:none;border-top-style:none;border-right-style:none">
                <img src="./research/gif/RHAML2.gif" alt="hpp" style="border-style: none" width="100%">
              </td>
              <td
                style="padding:10px;width:70%;vertical-align:middle;border-left-style:none;border-bottom-style:none;border-top-style:none;border-right-style:none">
                <p style="margin:0">
                  <t style="margin:0; font-size:100%; font-weight:bold"><big>RHAML: Rendezvous-based Hierarchical
                      Architecture for Mutual Localization</big></t> <br>
                  Gaoming Chen, <b>Kun Song</b>, Xiang Xu, Wenhang Liu, and Zhenhua Xiong
                  <br><i>Robotics and Automation Letters</i>, 2024
                  <div style="line-height:20px;font-size:18px;color: #777777">
                  <a href="https://ieeexplore.ieee.org/abstract/document/10540183" target="_blank">Paper</a>
                </div>
                <div style="line-height:20px;font-size:14px;color: #777777">
                We propose a novel rendezvous-based hierarchical architecture for mutual localization (RHAML). 
                Anisotropic convolutions are introduced into the network, yielding initial localization results and the iterative refinement module with rendering is employed. 
                Finally, the pose graph optimization is conducted to obtain more accurate results. 
                </div>
              </td>
            </tr>

            <tr>
              <td
                style="padding:10px;width:30%;vertical-align:middle;border-left-style:none;border-bottom-style:none;border-top-style:none;border-right-style:none">
                <img src="./research/image/fht_map.png" alt="hpp" style="border-style: none" width="100%">
              </td>
              <td
                style="padding:10px;width:70%;vertical-align:middle;border-left-style:none;border-bottom-style:none;border-top-style:none;border-right-style:none">
                <p style="margin:0">
                  <t style="margin:0; font-size:100%; font-weight:bold"><big>FHT-Map: Feature-based Hybrid Topological
                      Map for Relocalization and Path Planning</big></t> <br>
                  <b>Kun Song</b>, Wenhang Liu, Gaoming Chen, Xiang Xu, and Zhenhua Xiong
                  <br><i>Robotics and Automation Letters</i>, 2024
                <div style="line-height:20px;font-size:18px;color: #777777">
                  <a href="https://ieeexplore.ieee.org/document/10506547" target="_blank">Paper</a> /
                  <a href="https://github.com/song-kun/FHT-Map" target="_blank">Code</a>
                </div>
                <div style="line-height:20px;font-size:14px;color: #777777">
                We propose a feature-based hybrid topological map (FHT-Map) which consists of two types of nodes: main node and support node.
                Main nodes store compressed visual information and laser scan to enhance subsequent relocalization capability.
                Support nodes retain a minimal amount of data to ensure storage efficiency while facilitating path planning.
                </div>
              </td>
            </tr>

            <!-- <tr>
              <td
                style="padding:10px;width:30%;vertical-align:middle;border-left-style:none;border-bottom-style:none;border-top-style:none;border-right-style:none">
                <img src="./research/image/covidpre.png" alt="hpp" style="border-style: none" width="100%">
              </td>
              <td
                style="padding:10px;width:70%;vertical-align:middle;border-left-style:none;border-bottom-style:none;border-top-style:none;border-right-style:none">
                <p style="margin:0">
                  <t style="margin:0; font-size:100%; font-weight:bold"><big>Preliminary Assessment of the COVID-19 Outbreak Using 3-staged
                    Model e-ISHR</big></t> <br>
                  Sijia Li*, <b>Kun Song*</b>, Boran Yang*, Yucen Gao, and Xiaofeng Gao
                  <br><i>Journal of Shanghai Jiaotong University (Science)</i>, 2020
                <p style="line-height:10px;font-size:14px;color: #777777">
                  <a href="https://link.springer.com/article/10.1007/s12204-020-2169-0" target="_blank">Paper</a>
                </p>
                <p style="line-height:10px;font-size:14px;color: #777777"></p>
                We propose a 3-staged model e-ISHR to perform COVID-19 prediction.
                </p>

              </td>
            </tr> -->

          </tbody>
        </table>

        <hr/>
        Coming Soon
        <table>
          <tbody>
            <tr>
              <td
                style="padding:10px;width:30%;vertical-align:middle;border-left-style:none;border-bottom-style:none;border-top-style:none;border-right-style:none">
                <img src="./research/gif/DLG.gif" alt="hpp" style="border-style: none" width="100%">
              </td>
              <td
                style="padding:10px;width:70%;vertical-align:middle;border-left-style:none;border-bottom-style:none;border-top-style:none;border-right-style:none">
                <p style="margin:0">
                  <t style="margin:0; font-size:100%; font-weight:bold"><big>	A Novel Dynamic Localization Graph for Efficient Mutual Localization</big></t> <br>
                  Gaoming Chen, <b>Kun Song</b>, Wenhang Liu, Wenyao Ma, and Zhenhua Xiong
                  <br>Submitted; RAL, 2024
                <div style="line-height:20px;font-size:18px;color: #777777">
                  Paper / Code
                </div>
                <div style="line-height:20px;font-size:14px;color: #777777">
                  We propose <b>DLG</b>, a sensor-independent framework, to assess the uncertainty during the multi-robot mutual localization.
                  We validate the proposed method by implementing it on a place recognition based scenario.
                </div>
              </td>
            </tr>


            <tr>
              <td
                style="padding:10px;width:30%;vertical-align:middle;border-left-style:none;border-bottom-style:none;border-top-style:none;border-right-style:none">
                <img src="./research/gif/mmmcontrol.gif" alt="hpp" style="border-style: none" width="100%">
              </td>
              <td
                style="padding:10px;width:70%;vertical-align:middle;border-left-style:none;border-bottom-style:none;border-top-style:none;border-right-style:none">
                <p style="margin:0">
                  <t style="margin:0; font-size:100%; font-weight:bold"><big>Distributed Motion Control of Multiple
                      Mobile Manipulator System with Disturbance and Communication Delay</big></t> <br>
                  Wenhang Liu, Meng Ren, <b>Kun Song</b>, Michael Yu Wang, and Zhenhua Xiong
                  <br>Under Review; TASE, 2024
                <div style="line-height:20px;font-size:18px;color: #777777">
                  <a href="https://arxiv.org/abs/2406.05613" target="_blank">Paper</a>
                </div>
                <div style="line-height:20px;font-size:14px;color: #777777">
                We present a novel distributed motion control approach aimed at reducing the interaction forces between multiple mobile manipulators.
                The stability of the control law is rigorously proven by the Lyapunov theorem and the results are validated in simulations and experiments.
                </div>
              </td>
            </tr>


          </tbody>
        </table>

        <h2><a id="academic service" class="anchor" href="#publications" aria-hidden="true"><span
              class="octicon octicon-link"></span></a> Academic Services </h2>
        <li>
          <i>Conference Reviewer: AAAI, ICRA, IROS, AIM</i>
        </li>
        <li>
          <i>Journal Reviewer: T-RO, RA-L, RAS</i>
        </li>
        <br>

        <h2><a id="teaching" class="anchor" href="#publications" aria-hidden="true"><span
              class="octicon octicon-link"></span></a> Teaching </h2>
        <li>
          <i>TA:</i>
          COMP7308 Introduction to Unmanned Systems 2025 Fall

        </li>
        <li>
          <i>TA:</i>
          ME4409 Multi-robot system and control 2023 Fall

        </li>
        <li>
          <i>TA:</i>
          ME3403 Robotics 2024 Spring
        </li>
        <br>
        
        <div id="clustrmaps-container" style="width: 30%; margin: 0 auto;"></div>

        <script>
          if (window.location.protocol !== 'file:') {
            console.log("Online environment detected, loading ClustrMaps script.");
            var script = document.createElement('script');
            script.type = 'text/javascript';
            script.id = 'clustrmaps';
            script.src = '//clustrmaps.com/map_v2.js?d=oz9bKgR2vKBdG76LxLgjmeBj6UZq8zrWxKwuZ0bUDqE&cl=ffffff&w=a';

            var container = document.getElementById('clustrmaps-container');
            container.appendChild(script);  
          } else {
            console.log("Local environment detected, ClustrMaps script will not be loaded.");
          }
        </script>

        <script src="javascripts/scale.fix.js"></script>
        <script>
          var acc = document.getElementsByClassName("accordion");
          var i;

          for (i = 0; i < acc.length; i++) {
            acc[i].onclick = function () {
              this.classList.toggle("active");
              this.parentNode.nextElementSibling.classList.toggle("show");
            }
          }
        </script>
      </section>
    </section>
  </div>
    


</body>

</html>